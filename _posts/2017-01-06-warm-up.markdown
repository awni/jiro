---
layout: post
title: "A simple warm-up."
date: 2017-01-06
categories: [practice]
tags: [neural networks]
difficulty: 0
---

### Problem ###

The logistic sigmoid function is one of the more commonly used activation
functions for neural networks. The function is given by

\begin{align}
\sigma(x) = \frac{1}{1+ e^{-x}}
\end{align}

One of the nice properties of this funciton is that its derivative can be
written in terms of the function value itself.

Show that $$\frac{d}{dx} \sigma(x) = \sigma(x) (1 - \sigma(x))$$.

### Solution ###
<a id='answer-toggle' href="#" onclick="toggleDiv()">show</a>

<span id="answer-block"  style="display:none;">
The derivative of $$\sigma(x)$$ can be written as 

\begin{align}
\frac{d}{dx} \sigma(x) &= \frac{d}{dx} \frac{1}{1+ e^{-x}} \\\
&= \frac{e^{-x}}{(1 + e^{-x})^{2}} \\\
&= \frac{e^{-x} + 1 - 1}{(1+e^{-x})^2} \\\
&= \frac{1}{1+e^{-x}} \left(\frac{1+e^{-x}}{1+e^{-x}} - \frac{1}{1+e^{-x}}  \right)\\\
&= \sigma(x) (1 - \sigma(x))
\end{align}
</span>
