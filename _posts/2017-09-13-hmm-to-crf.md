---
layout: post
title: "CRFs Generalize HMMs"
date: 2017-09-13
categories: [practice]
tags: [sequence models]
difficulty: 1
---

### Problem ###

The Hidden Markov Model (HMM) is a generative model. An HMM models the joint
probability of two sequences as 
\begin{align}
p(X, Y) = \prod\_{t=1}^T p(x_t \mid y_t) p(y_t \mid y\_{t-1}).
\end{align}

The Conditional Random Field (CRF) is a discriminative model. A linear-chain
CRF models the conditional
probability of $$Y$$ given $$X$$ as
\begin{align}
p(Y \mid X) = \frac{1}{Z} \prod\_{t=1}^T \exp
 \left\lbrace \sum\_{m=1}^M \mu_m f_m(x_t, y_t, y\_{t-1}) \right\rbrace
\end{align}

A nice property of the linear-chain CRF is that it is a strict generalization
of the HMM. Any distribution representable by an HMM can be modeled by a CRF.
Show that this is true.

### Solution ###
<a id='answer-toggle' href="#" onclick="toggleDiv()">show</a>

<div id="answer-block"  style="display:none;" markdown="1">

We can convert an HMM into a CRF as follows. Assume the variable $$x_t$$ can
take on $$p$$ values and $$y_t$$ can take on $$q$$ values. Thus we need
$$M = pq + q^2$$ factors. The factors will be 
\begin{align}
g\_{i, j}(x_t, y_t, y\_{t-1}) &= \mathbb{1}\lbrace x_t = i, y_t = j \rbrace \\\
h\_{j, k}(x_t, y_t, y\_{t-1}) &= \mathbb{1}\lbrace y_t = j, y\_{t-1} = k \rbrace.
\end{align}

The weights will be

\begin{align}
\lambda\_{i, j} &= \log p(x_t = i \mid y_t = j) \\\
\theta\_{j, k} &= \log p(y_t = j \mid y\_{t-1} = k)
\end{align}
and let $$Z = 1$$.

Now the HMM can be written as
\begin{align}
&\prod\_{t=1}^T p(x_t = i \mid y_t = j) p(y_t = j \mid y\_{t-1} = k)  \\\
= &\prod\_{t=1}^T \exp \left\lbrace \lambda\_{i, j} + \theta\_{j, k} \right\rbrace \\\
= &\prod\_{t=1}^T \exp \left\lbrace \sum\_{i,j} \lambda\_{i, j} \mathbb{1} \lbrace x_t = i, y_t = j \rbrace + \sum\_{j, k} \theta\_{j, k} \mathbb{1} \lbrace y_t = j, y\_{t-1} = k \rbrace \right\rbrace\\\
= &\frac{1}{Z} \prod\_{t=1}^T \exp \left\lbrace \sum\_{i,j} \lambda\_{i,j} g\_{i,j}(x_t, y_t, y\_{t-1}) + \sum\_{j,k} \theta\_{j,k} h\_{j,k}(x_t, y_t, y\_{t-1}) \right\rbrace \\\
= &\frac{1}{Z} \prod\_{t=1}^T \exp \left\lbrace \sum\_{m = 1}^M \mu\_{m} f_{m}(x_t, y_t, y\_{t-1})  \right\rbrace.
\end{align}

In the final step we combine all the factors into a single summation to show
the equivalence to a CRF. In this case the factors are
\begin{align}
f\_{i + p (j - 1)}(\cdot) &= g\_{i,j}(\cdot) \\\
f\_{pq + j + q (k - 1)}(\cdot) &= h\_{j, k}(\cdot)
\end{align}
and the weights are
\begin{align}
\mu\_{i + p (j - 1)} &= \lambda\_{i,j} \\\
\mu\_{pq + j + q (k - 1)} &= \theta\_{j, k}.
\end{align}

</div>

<span class="post-credit">
This fact was pointed out to me in Section 2.3 of [An Introduction to
Conditional Random
Fields](http://homepages.inf.ed.ac.uk/csutton/publications/crftut-fnt.pdf).
</span>
